{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 104884,
     "sourceType": "datasetVersion",
     "datasetId": 54339
    }
   ],
   "dockerImageVersionId": 30698,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  },
  "colab": {
   "provenance": [
    {
     "file_id": "https://storage.googleapis.com/kaggle-colab-exported-notebooks/skin-cancer-classification-cnn-f905a350-c1b3-4faf-b39c-ac0354dd376b.ipynb?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com/20240509/auto/storage/goog4_request&X-Goog-Date=20240509T042117Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=9b8423bf4dcd7cb87ca4e96b5654877d76db2f0f49023983bad05c4f445e49cee5282706de839868d20fa792a065bbdde94b0038936217f54fecba2216ab54105e6b70e57baace989195dc9b71169b847ac224796e27a6ae51ed31bdf22a900304c548ff4832d5e988a9623d200d318d39ee8e0ad63ee67f87ea4475be6bf6838b23d898ec5136834c63cc4b4449442210cc73b72097784861a70da6fc2f0f2251e98cd29b9cd6bb85f0cd21100f8ebccea5d4ba4e3ae9975bd252c01ca40c80c063d31e109d4778a6997283c463ee0e661f6c235afae0802e55cdd632177c35e71aa16a35fd7eb994c8a7276131e399c4714e8631111542ea894132a7a263ea",
     "timestamp": 1715228527821
    }
   ]
  }
 },
 "nbformat_minor": 0,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "# Importing required libraries\nimport pandas as pd\nimport numpy as np\nimport os\nfrom glob import glob\nfrom PIL import Image\nimport itertools\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.utils import resample\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom keras.utils import to_categorical\nfrom tensorflow.keras.applications import ResNet50, MobileNet, DenseNet121\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization, Conv2D, MaxPooling2D, Input, GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport tensorflow.keras.backend as K\nimport tensorflow as tf",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T11:40:28.032447Z",
     "iopub.execute_input": "2024-05-08T11:40:28.033321Z",
     "iopub.status.idle": "2024-05-08T11:40:38.169351Z",
     "shell.execute_reply.started": "2024-05-08T11:40:28.033285Z",
     "shell.execute_reply": "2024-05-08T11:40:38.168332Z"
    },
    "trusted": true,
    "id": "PUKvomBzlZrh"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T11:40:38.171438Z",
     "iopub.execute_input": "2024-05-08T11:40:38.172114Z",
     "iopub.status.idle": "2024-05-08T11:40:38.176951Z",
     "shell.execute_reply.started": "2024-05-08T11:40:38.17208Z",
     "shell.execute_reply": "2024-05-08T11:40:38.175751Z"
    },
    "trusted": true,
    "id": "8n9J3dkZlZri"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Read metadata\nskinDf = pd.read_csv('/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv')\n\n# Set image size (matching paper specification: 120x120)\nimg_size = (120, 120)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T11:40:38.178872Z",
     "iopub.execute_input": "2024-05-08T11:40:38.179338Z",
     "iopub.status.idle": "2024-05-08T11:40:38.226378Z",
     "shell.execute_reply.started": "2024-05-08T11:40:38.1793Z",
     "shell.execute_reply": "2024-05-08T11:40:38.225465Z"
    },
    "trusted": true,
    "id": "E0pl37SSlZri"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# ============================================\n# FOCAL LOSS IMPLEMENTATION\n# ============================================\n# Focal Loss helps the model focus on hard-to-classify examples (minority classes)\ndef focal_loss(gamma=2., alpha=0.25):\n    \"\"\"\n    Focal loss for multi-classification\n    FL(p_t) = -alpha * (1 - p_t)^gamma * log(p_t)\n    \n    gamma: focusing parameter (default=2)\n    alpha: balancing parameter (default=0.25)\n    \"\"\"\n    def focal_loss_fixed(y_true, y_pred):\n        epsilon = K.epsilon()\n        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n        cross_entropy = -y_true * K.log(y_pred)\n        loss = alpha * K.pow(1 - y_pred, gamma) * cross_entropy\n        return K.sum(loss, axis=-1)\n    return focal_loss_fixed\n\n# ============================================\n# WEIGHTED CATEGORICAL CROSS-ENTROPY\n# ============================================\ndef weighted_categorical_crossentropy(weights):\n    \"\"\"\n    Weighted cross-entropy loss that gives more importance to minority classes\n    weights: array of weights for each class\n    \"\"\"\n    weights = K.variable(weights)\n    def loss(y_true, y_pred):\n        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n        loss = y_true * K.log(y_pred) * weights\n        loss = -K.sum(loss, -1)\n        return loss\n    return loss\n\nprint(\"Loss functions loaded successfully!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Encode labels\nlabelEncoder = LabelEncoder()\nskinDf['label'] = labelEncoder.fit_transform(skinDf['dx'])\n\n# Print original class distribution\nprint(\"Original Class Distribution:\")\nprint(skinDf['dx'].value_counts())\nprint(\"\\nClass label mapping:\")\nfor i, class_name in enumerate(labelEncoder.classes_):\n    print(f\"Class {i}: {class_name} ({len(skinDf[skinDf['label'] == i])} images)\")\n\n# ============================================\n# STRATEGY 1: Intelligent Resampling\n# ============================================\n# Instead of balancing to same count, we'll use a hybrid approach:\n# - Oversample minority classes with augmentation\n# - Keep majority classes at reasonable levels\n\n# Define target samples per class (based on sqrt of max class size for better balance)\nmax_samples = skinDf['label'].value_counts().max()\ntarget_samples = int(np.sqrt(max_samples) * 50)  # ~4000 samples per class\n\nprint(f\"\\nTarget samples per class: {target_samples}\")\n\ndfs_by_label_resampled = {}\nfor label in range(7):\n    df_label = skinDf[skinDf['label'] == label]\n    current_count = len(df_label)\n    \n    if current_count < target_samples:\n        # Oversample minority classes\n        df_label_resampled = resample(df_label, \n                                       n_samples=target_samples, \n                                       replace=True, \n                                       random_state=42)\n    else:\n        # Keep majority class but don't reduce too much\n        df_label_resampled = resample(df_label, \n                                       n_samples=min(current_count, target_samples), \n                                       replace=False, \n                                       random_state=42)\n    \n    dfs_by_label_resampled[label] = df_label_resampled\n    print(f\"Class {label}: {current_count} -> {len(df_label_resampled)} images\")\n\nbalanced_df = pd.concat(dfs_by_label_resampled.values()).sample(frac=1, random_state=42).reset_index(drop=True)\n\nprint(f\"\\nTotal balanced dataset size: {len(balanced_df)}\")\nprint(f\"Expected training size (60%): {int(len(balanced_df) * 0.6)}\")",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T11:40:38.227685Z",
     "iopub.execute_input": "2024-05-08T11:40:38.228006Z",
     "iopub.status.idle": "2024-05-08T11:40:38.265052Z",
     "shell.execute_reply.started": "2024-05-08T11:40:38.22798Z",
     "shell.execute_reply": "2024-05-08T11:40:38.264049Z"
    },
    "trusted": true,
    "id": "19fdMj7ElZri"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Load images\nimgPath = {os.path.splitext(os.path.basename(x))[0]: x for x in glob(os.path.join('/kaggle/input/skin-cancer-mnist-ham10000/', '*', '*.jpg'))}\nbalanced_df['image'] = balanced_df['image_id'].map(imgPath.get).map(lambda x: np.asarray(Image.open(x).resize(img_size)) / 255)\n\n# Prepare features and labels\nx = np.asarray(balanced_df['image'].to_list())\ny = to_categorical(balanced_df['label'], num_classes=7)\n\n# Split data: 60% train, 20% validation, 20% test (as per paper section 3.2)\nx_train, x_temp, y_train, y_temp = train_test_split(x, y, test_size=0.4, random_state=42, shuffle=True, stratify=y)\nx_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42, shuffle=True, stratify=y_temp)\n\nprint(f\"Training set: {x_train.shape}\")\nprint(f\"Validation set: {x_val.shape}\")\nprint(f\"Test set: {x_test.shape}\")\n\n# ============================================\n# STRATEGY 2: Calculate Class Weights\n# ============================================\n# Calculate class weights to give more importance to minority classes in loss function\ny_train_labels = np.argmax(y_train, axis=1)\nclass_weights = compute_class_weight(\n    class_weight='balanced',\n    classes=np.unique(y_train_labels),\n    y=y_train_labels\n)\n\n# Convert to dictionary format for Keras\nclass_weight_dict = dict(enumerate(class_weights))\n\nprint(\"\\nClass Weights (higher = more important):\")\nfor i, weight in class_weight_dict.items():\n    class_name = labelEncoder.classes_[i]\n    print(f\"Class {i} ({class_name}): {weight:.3f}\")",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T11:40:38.268341Z",
     "iopub.execute_input": "2024-05-08T11:40:38.269235Z",
     "iopub.status.idle": "2024-05-08T11:41:55.438105Z",
     "shell.execute_reply.started": "2024-05-08T11:40:38.269202Z",
     "shell.execute_reply": "2024-05-08T11:41:55.436909Z"
    },
    "trusted": true,
    "id": "B66I76iflZrj"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "tgjJFKjHlZrj"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# ============================================\n# STRATEGY 3: Data Augmentation\n# ============================================\n# Apply aggressive augmentation to training data to improve generalization\n# This is especially important for minority classes\n\ntrain_datagen = ImageDataGenerator(\n    rotation_range=40,           # Randomly rotate images by up to 40 degrees\n    width_shift_range=0.2,       # Randomly shift images horizontally (20%)\n    height_shift_range=0.2,      # Randomly shift images vertically (20%)\n    shear_range=0.2,             # Shear transformation\n    zoom_range=0.2,              # Random zoom\n    horizontal_flip=True,        # Randomly flip images horizontally\n    vertical_flip=True,          # Randomly flip images vertically\n    brightness_range=[0.8, 1.2], # Adjust brightness\n    fill_mode='nearest'          # Fill newly created pixels\n)\n\n# Validation and test data should NOT be augmented\nval_datagen = ImageDataGenerator()\ntest_datagen = ImageDataGenerator()\n\n# Create generators\nbatch_size = 32  # Increased from 8 for better training stability\n\ntrain_generator = train_datagen.flow(x_train, y_train, batch_size=batch_size, shuffle=True)\nval_generator = val_datagen.flow(x_val, y_val, batch_size=batch_size, shuffle=False)\n\nprint(\"Data augmentation configured successfully!\")\nprint(f\"Batch size: {batch_size}\")\nprint(f\"Steps per epoch: {len(x_train) // batch_size}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# ============================================\n# MODEL COMPILATION WITH IMPROVED LOSS FUNCTION\n# ============================================\n# Options: 'categorical_crossentropy', 'focal_loss', 'weighted_crossentropy'\nLOSS_FUNCTION = 'focal_loss'  # Change this to experiment\n\nif LOSS_FUNCTION == 'focal_loss':\n    loss = focal_loss(gamma=2.0, alpha=0.25)\n    print(\"Using Focal Loss (focuses on hard-to-classify examples)\")\nelif LOSS_FUNCTION == 'weighted_crossentropy':\n    loss = weighted_categorical_crossentropy(class_weights)\n    print(\"Using Weighted Categorical Cross-Entropy\")\nelse:\n    loss = 'categorical_crossentropy'\n    print(\"Using standard Categorical Cross-Entropy\")\n\n# Compile model with optimized learning rate\nmodel.compile(\n    optimizer=Adam(learning_rate=0.0001),\n    loss=loss,\n    metrics=['accuracy']\n)\n\nprint(f\"\\nModel compiled with {LOSS_FUNCTION}\")",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ============================================\n# TRAINING WITH ALL IMPROVEMENTS\n# ============================================\n\n# Callbacks for better training\ncallbacks = [\n    # Stop training if validation loss doesn't improve for 10 epochs\n    EarlyStopping(\n        monitor='val_loss',\n        patience=10,\n        restore_best_weights=True,\n        verbose=1\n    ),\n    \n    # Reduce learning rate when validation loss plateaus\n    ReduceLROnPlateau(\n        monitor='val_loss',\n        factor=0.2,\n        patience=5,\n        min_lr=0.00001,\n        verbose=1\n    ),\n    \n    # Save best model\n    ModelCheckpoint(\n        'best_model.h5',\n        monitor='val_accuracy',\n        save_best_only=True,\n        verbose=1\n    )\n]\n\n# Train model with data augmentation and class weights\nprint(\"\\n\" + \"=\"*50)\nprint(\"TRAINING MODEL WITH ALL IMPROVEMENTS\")\nprint(\"=\"*50)\nprint(\"✓ Data Augmentation: Enabled\")\nprint(\"✓ Class Weights: Enabled\")\nprint(f\"✓ Loss Function: {LOSS_FUNCTION}\")\nprint(\"✓ Early Stopping: Enabled\")\nprint(\"✓ Learning Rate Reduction: Enabled\")\nprint(\"=\"*50 + \"\\n\")\n\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=len(x_train) // batch_size,\n    epochs=200,\n    validation_data=val_generator,\n    validation_steps=len(x_val) // batch_size,\n    callbacks=callbacks,\n    class_weight=class_weight_dict,  # Apply class weights\n    verbose=1\n)\n\nprint(\"\\nTraining completed!\")",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T11:41:55.439473Z",
     "iopub.execute_input": "2024-05-08T11:41:55.439803Z",
     "iopub.status.idle": "2024-05-08T11:41:55.886521Z",
     "shell.execute_reply.started": "2024-05-08T11:41:55.439776Z",
     "shell.execute_reply": "2024-05-08T11:41:55.885635Z"
    },
    "trusted": true,
    "id": "ipFFBgeXlZrj"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# ============================================\n# MODEL EVALUATION WITH DETAILED METRICS\n# ============================================\n\n# Evaluate on test set\ntest_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"TEST SET RESULTS\")\nprint(\"=\"*50)\nprint(f'Overall Test Accuracy: {test_accuracy*100:.2f}%')\nprint(f'Overall Test Loss: {test_loss:.4f}')\nprint(\"=\"*50)\n\n# Get predictions\ny_pred = model.predict(x_test, verbose=0)\ny_true_int = np.argmax(y_test, axis=1)\ny_pred_int = np.argmax(y_pred, axis=1)\n\n# ============================================\n# PER-CLASS ACCURACY (Most Important!)\n# ============================================\nprint(\"\\n\" + \"=\"*50)\nprint(\"PER-CLASS ACCURACY\")\nprint(\"=\"*50)\n\nclass_accuracies = []\nfor i in range(7):\n    class_name = labelEncoder.classes_[i]\n    # Find indices where true label is this class\n    class_indices = np.where(y_true_int == i)[0]\n    if len(class_indices) > 0:\n        # Calculate accuracy for this class\n        class_correct = np.sum(y_pred_int[class_indices] == i)\n        class_total = len(class_indices)\n        class_acc = (class_correct / class_total) * 100\n        class_accuracies.append(class_acc)\n        \n        status = \"✓\" if class_acc >= 90 else \"✗\" if class_acc < 80 else \"~\"\n        print(f\"{status} Class {i} ({class_name:30s}): {class_acc:6.2f}% ({class_correct}/{class_total})\")\n    else:\n        class_accuracies.append(0)\n        print(f\"✗ Class {i} ({class_name:30s}): No test samples\")\n\nprint(\"=\"*50)\nprint(f\"Average Per-Class Accuracy: {np.mean(class_accuracies):.2f}%\")\nprint(f\"Minimum Class Accuracy: {np.min(class_accuracies):.2f}%\")\nprint(f\"Maximum Class Accuracy: {np.max(class_accuracies):.2f}%\")\nprint(\"=\"*50)\n\n# ============================================\n# DETAILED CLASSIFICATION REPORT\n# ============================================\nprint(\"\\n\" + \"=\"*50)\nprint(\"DETAILED CLASSIFICATION REPORT\")\nprint(\"=\"*50)\nprint(classification_report(y_true_int, y_pred_int, \n                          target_names=labelEncoder.classes_,\n                          digits=4))\n\n# ============================================\n# CONFUSION MATRIX\n# ============================================\ncm = confusion_matrix(y_true_int, y_pred_int)\n\nplt.figure(figsize=(12, 10))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=labelEncoder.classes_,\n            yticklabels=labelEncoder.classes_)\nplt.xlabel('Predicted', fontsize=12)\nplt.ylabel('True', fontsize=12)\nplt.title('Confusion Matrix - Skin Cancer Classification', fontsize=14)\nplt.xticks(rotation=45, ha='right')\nplt.yticks(rotation=0)\nplt.tight_layout()\nplt.show()\n\n# ============================================\n# TRAINING HISTORY VISUALIZATION\n# ============================================\nfig, axes = plt.subplots(1, 2, figsize=(15, 5))\n\n# Plot accuracy\naxes[0].plot(history.history['accuracy'], label='Training Accuracy')\naxes[0].plot(history.history['val_accuracy'], label='Validation Accuracy')\naxes[0].set_title('Model Accuracy Over Time', fontsize=14)\naxes[0].set_xlabel('Epoch')\naxes[0].set_ylabel('Accuracy')\naxes[0].legend()\naxes[0].grid(True, alpha=0.3)\n\n# Plot loss\naxes[1].plot(history.history['loss'], label='Training Loss')\naxes[1].plot(history.history['val_loss'], label='Validation Loss')\naxes[1].set_title('Model Loss Over Time', fontsize=14)\naxes[1].set_xlabel('Epoch')\naxes[1].set_ylabel('Loss')\naxes[1].legend()\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T11:41:55.887852Z",
     "iopub.execute_input": "2024-05-08T11:41:55.888184Z",
     "iopub.status.idle": "2024-05-08T11:41:55.903091Z",
     "shell.execute_reply.started": "2024-05-08T11:41:55.888155Z",
     "shell.execute_reply": "2024-05-08T11:41:55.901923Z"
    },
    "trusted": true,
    "id": "UySC9XtQlZrk"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# ============================================\n# EXPORT RESULTS FOR PAPER\n# ============================================\nprint(\"\\n\" + \"=\"*50)\nprint(\"EXPORTING RESULTS FOR PAPER\")\nprint(\"=\"*50)\n\n# Create output directory\nimport os\nos.makedirs('paper_results', exist_ok=True)\n\n# 1. Export Per-Class Accuracy to CSV\nclass_results = []\nfor i in range(7):\n    class_name = labelEncoder.classes_[i]\n    class_indices = np.where(y_true_int == i)[0]\n    if len(class_indices) > 0:\n        class_correct = np.sum(y_pred_int[class_indices] == i)\n        class_total = len(class_indices)\n        class_acc = (class_correct / class_total) * 100\n        \n        # Calculate precision, recall, f1 for this class\n        tp = class_correct\n        fp = np.sum((y_pred_int == i) & (y_true_int != i))\n        fn = class_total - class_correct\n        \n        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n        \n        class_results.append({\n            'Class': i,\n            'Disease': class_name,\n            'True_Positives': tp,\n            'False_Positives': fp,\n            'False_Negatives': fn,\n            'Total_Samples': class_total,\n            'Accuracy': class_acc,\n            'Precision': precision * 100,\n            'Recall': recall * 100,\n            'F1_Score': f1 * 100\n        })\n\ndf_class_results = pd.DataFrame(class_results)\ndf_class_results.to_csv('paper_results/per_class_metrics.csv', index=False)\nprint(\"✓ Saved: paper_results/per_class_metrics.csv\")\n\n# 2. Export Overall Model Performance\noverall_results = {\n    'Model_Type': [MODEL_TYPE],\n    'Loss_Function': [LOSS_FUNCTION],\n    'Overall_Test_Accuracy': [test_accuracy * 100],\n    'Overall_Test_Loss': [test_loss],\n    'Average_Per_Class_Accuracy': [np.mean([r['Accuracy'] for r in class_results])],\n    'Min_Class_Accuracy': [np.min([r['Accuracy'] for r in class_results])],\n    'Max_Class_Accuracy': [np.max([r['Accuracy'] for r in class_results])],\n    'Training_Samples': [len(x_train)],\n    'Validation_Samples': [len(x_val)],\n    'Test_Samples': [len(x_test)],\n    'Data_Augmentation': ['Yes'],\n    'Class_Weights': ['Yes'],\n    'Batch_Size': [batch_size]\n}\ndf_overall = pd.DataFrame(overall_results)\ndf_overall.to_csv('paper_results/overall_model_performance.csv', index=False)\nprint(\"✓ Saved: paper_results/overall_model_performance.csv\")\n\n# 3. Export Confusion Matrix to CSV\ndf_cm = pd.DataFrame(cm, \n                     index=[f\"{i}_{name}\" for i, name in enumerate(labelEncoder.classes_)],\n                     columns=[f\"{i}_{name}\" for i, name in enumerate(labelEncoder.classes_)])\ndf_cm.to_csv('paper_results/confusion_matrix.csv')\nprint(\"✓ Saved: paper_results/confusion_matrix.csv\")\n\n# 4. Export Training History\ndf_history = pd.DataFrame({\n    'Epoch': range(1, len(history.history['accuracy']) + 1),\n    'Training_Accuracy': history.history['accuracy'],\n    'Validation_Accuracy': history.history['val_accuracy'],\n    'Training_Loss': history.history['loss'],\n    'Validation_Loss': history.history['val_loss']\n})\ndf_history.to_csv('paper_results/training_history.csv', index=False)\nprint(\"✓ Saved: paper_results/training_history.csv\")\n\n# 5. Save Confusion Matrix as Image\nplt.figure(figsize=(14, 12))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=labelEncoder.classes_,\n            yticklabels=labelEncoder.classes_,\n            cbar_kws={'label': 'Count'})\nplt.xlabel('Predicted Class', fontsize=14, fontweight='bold')\nplt.ylabel('True Class', fontsize=14, fontweight='bold')\nplt.title(f'Confusion Matrix - {MODEL_TYPE.upper()} Model\\nOverall Accuracy: {test_accuracy*100:.2f}%', \n          fontsize=16, fontweight='bold')\nplt.xticks(rotation=45, ha='right')\nplt.yticks(rotation=0)\nplt.tight_layout()\nplt.savefig('paper_results/confusion_matrix.png', dpi=300, bbox_inches='tight')\nplt.savefig('paper_results/confusion_matrix.pdf', bbox_inches='tight')\nprint(\"✓ Saved: paper_results/confusion_matrix.png\")\nprint(\"✓ Saved: paper_results/confusion_matrix.pdf\")\nplt.close()\n\n# 6. Save Training History Plot\nfig, axes = plt.subplots(1, 2, figsize=(16, 6))\n\n# Accuracy plot\naxes[0].plot(history.history['accuracy'], label='Training', linewidth=2, marker='o', markersize=3)\naxes[0].plot(history.history['val_accuracy'], label='Validation', linewidth=2, marker='s', markersize=3)\naxes[0].set_title('Model Accuracy Over Time', fontsize=14, fontweight='bold')\naxes[0].set_xlabel('Epoch', fontsize=12)\naxes[0].set_ylabel('Accuracy', fontsize=12)\naxes[0].legend(fontsize=11)\naxes[0].grid(True, alpha=0.3)\n\n# Loss plot\naxes[1].plot(history.history['loss'], label='Training', linewidth=2, marker='o', markersize=3)\naxes[1].plot(history.history['val_loss'], label='Validation', linewidth=2, marker='s', markersize=3)\naxes[1].set_title('Model Loss Over Time', fontsize=14, fontweight='bold')\naxes[1].set_xlabel('Epoch', fontsize=12)\naxes[1].set_ylabel('Loss', fontsize=12)\naxes[1].legend(fontsize=11)\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('paper_results/training_history.png', dpi=300, bbox_inches='tight')\nplt.savefig('paper_results/training_history.pdf', bbox_inches='tight')\nprint(\"✓ Saved: paper_results/training_history.png\")\nprint(\"✓ Saved: paper_results/training_history.pdf\")\nplt.close()\n\n# 7. Save Per-Class Accuracy Bar Chart\nplt.figure(figsize=(14, 8))\nclass_names_short = [name[:20] for name in labelEncoder.classes_]\naccuracies = [r['Accuracy'] for r in class_results]\ncolors = ['green' if acc >= 90 else 'orange' if acc >= 80 else 'red' for acc in accuracies]\n\nbars = plt.bar(range(7), accuracies, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\nplt.axhline(y=90, color='green', linestyle='--', linewidth=2, label='90% Target', alpha=0.5)\nplt.axhline(y=80, color='orange', linestyle='--', linewidth=2, label='80% Threshold', alpha=0.5)\n\n# Add value labels on bars\nfor i, (bar, acc) in enumerate(zip(bars, accuracies)):\n    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n             f'{acc:.1f}%', ha='center', va='bottom', fontsize=11, fontweight='bold')\n\nplt.xlabel('Disease Class', fontsize=14, fontweight='bold')\nplt.ylabel('Accuracy (%)', fontsize=14, fontweight='bold')\nplt.title(f'Per-Class Accuracy - {MODEL_TYPE.upper()} Model', fontsize=16, fontweight='bold')\nplt.xticks(range(7), class_names_short, rotation=45, ha='right', fontsize=10)\nplt.ylim(0, 105)\nplt.legend(fontsize=11)\nplt.grid(True, alpha=0.3, axis='y')\nplt.tight_layout()\nplt.savefig('paper_results/per_class_accuracy.png', dpi=300, bbox_inches='tight')\nplt.savefig('paper_results/per_class_accuracy.pdf', bbox_inches='tight')\nprint(\"✓ Saved: paper_results/per_class_accuracy.png\")\nprint(\"✓ Saved: paper_results/per_class_accuracy.pdf\")\nplt.close()\n\n# 8. Create Summary Report\nsummary_text = f\"\"\"\nSKIN CANCER CLASSIFICATION - MODEL PERFORMANCE REPORT\n{'='*70}\n\nMODEL CONFIGURATION:\n  - Model Type: {MODEL_TYPE.upper()}\n  - Loss Function: {LOSS_FUNCTION}\n  - Data Augmentation: Yes\n  - Class Weights: Yes\n  - Batch Size: {batch_size}\n  \nDATASET SPLIT:\n  - Training Samples: {len(x_train)}\n  - Validation Samples: {len(x_val)}\n  - Test Samples: {len(x_test)}\n\nOVERALL PERFORMANCE:\n  - Overall Test Accuracy: {test_accuracy*100:.2f}%\n  - Overall Test Loss: {test_loss:.4f}\n  - Average Per-Class Accuracy: {np.mean([r['Accuracy'] for r in class_results]):.2f}%\n  - Minimum Class Accuracy: {np.min([r['Accuracy'] for r in class_results]):.2f}%\n  - Maximum Class Accuracy: {np.max([r['Accuracy'] for r in class_results]):.2f}%\n\nPER-CLASS PERFORMANCE:\n{'='*70}\n\"\"\"\n\nfor result in class_results:\n    summary_text += f\"\"\"\nClass {result['Class']}: {result['Disease']}\n  - Accuracy: {result['Accuracy']:.2f}%\n  - Precision: {result['Precision']:.2f}%\n  - Recall: {result['Recall']:.2f}%\n  - F1-Score: {result['F1_Score']:.2f}%\n  - Test Samples: {result['Total_Samples']}\n\"\"\"\n\nsummary_text += f\"\\n{'='*70}\\n\"\n\nwith open('paper_results/model_summary_report.txt', 'w') as f:\n    f.write(summary_text)\nprint(\"✓ Saved: paper_results/model_summary_report.txt\")\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"ALL RESULTS EXPORTED SUCCESSFULLY!\")\nprint(\"Check the 'paper_results' folder for:\")\nprint(\"  - CSV files (metrics, confusion matrix, training history)\")\nprint(\"  - PNG images (high resolution, for presentations)\")\nprint(\"  - PDF files (vector format, for papers)\")\nprint(\"  - TXT summary report\")\nprint(\"=\"*50)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Reduce learning rate when a metric has stopped improving\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00001)\n\n# Train model (using validation set for validation, not test set)\nhistory = model.fit(x_train, y_train, epochs=200, batch_size=8, validation_data=(x_val, y_val), callbacks=[EarlyStopping(patience=5), reduce_lr])",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T11:41:55.904357Z",
     "iopub.execute_input": "2024-05-08T11:41:55.904728Z",
     "iopub.status.idle": "2024-05-08T11:45:16.419977Z",
     "shell.execute_reply.started": "2024-05-08T11:41:55.904699Z",
     "shell.execute_reply": "2024-05-08T11:45:16.418895Z"
    },
    "trusted": true,
    "id": "ynVN_QsXlZrk"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Predict on test set\ny_pred = model.predict(x_test)\n\n# Convert one-hot encoded labels to integer labels\ny_true_int = np.argmax(y_test, axis=1)\ny_pred_int = np.argmax(y_pred, axis=1)\n\n# Generate confusion matrix\ncm = confusion_matrix(y_true_int, y_pred_int)\n\n# Plot confusion matrix\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5', 'Class 6'],\n            yticklabels=['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5', 'Class 6'])\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T11:45:16.421666Z",
     "iopub.execute_input": "2024-05-08T11:45:16.422036Z",
     "iopub.status.idle": "2024-05-08T11:45:28.575155Z",
     "shell.execute_reply.started": "2024-05-08T11:45:16.422004Z",
     "shell.execute_reply": "2024-05-08T11:45:28.574089Z"
    },
    "trusted": true,
    "id": "X5qYtaJElZrk"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "y_pred = model.predict(x_test)\n",
    "import seaborn as sns\n",
    "\n",
    "# Convert one-hot encoded labels to integer labels\n",
    "y_true_int = np.argmax(y_test, axis=1)\n",
    "y_pred_int = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_true_int, y_pred_int)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5', 'Class 6'],\n",
    "            yticklabels=['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5', 'Class 6'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T11:45:29.339322Z",
     "iopub.execute_input": "2024-05-08T11:45:29.340251Z",
     "iopub.status.idle": "2024-05-08T11:45:41.475662Z",
     "shell.execute_reply.started": "2024-05-08T11:45:29.34021Z",
     "shell.execute_reply": "2024-05-08T11:45:41.474617Z"
    },
    "trusted": true,
    "id": "b3guAPzUlZrk"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}